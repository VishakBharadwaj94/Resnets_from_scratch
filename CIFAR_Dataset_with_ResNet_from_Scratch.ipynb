{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR_Dataset_with_ResNet_from_Scratch",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishakBharadwaj94/Resnets_from_scratch/blob/master/CIFAR_Dataset_with_ResNet_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BDjwUDIgCE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urLU8eRFg1s6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlock(nn.Module):     \n",
        "  expansion = 1\n",
        "  def __init__(self, in_channels, out_channels, stride=1):\n",
        "    super(ResBlock, self).__init__()\n",
        "\n",
        "    # Conv Layer 1\n",
        "    self.conv1 = nn.Conv2d(\n",
        "        in_channels=in_channels, out_channels=out_channels,\n",
        "        kernel_size=(3, 3), stride=stride, padding=1, bias=False\n",
        "    )\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    # Conv Layer 2\n",
        "    self.conv2 = nn.Conv2d(\n",
        "        in_channels=out_channels, out_channels=out_channels,\n",
        "        kernel_size=(3, 3), stride=1, padding=1, bias=False\n",
        "    )\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_channels != out_channels:\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(\n",
        "              in_channels=in_channels, out_channels=out_channels,\n",
        "              kernel_size=(1, 1), stride=stride, bias=False\n",
        "          ),\n",
        "          nn.BatchNorm2d(out_channels)\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = nn.ReLU()(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmnSaYW7lRBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "  def __init__(self,classes=10):\n",
        "\n",
        "    super(ResNet,self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=3,out_channels=64,kernel_size=(3,3),stride=1, padding=1,bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.rel1 = nn.ReLU()\n",
        "\n",
        "    self.block1 = self.create_block(64,64,1)\n",
        "    self.block2 = self.create_block(64,128,2)\n",
        "    self.block3 = self.create_block(128,256,2)\n",
        "    self.block4 = self.create_block(256,512,2)\n",
        "\n",
        "    self.lin = nn.Linear(512,classes)\n",
        "\n",
        "    #1 block has two reblocks\n",
        "\n",
        "  def create_block(self, in_channels, out_channels, stride):\n",
        "    \n",
        "    net = nn.Sequential(\n",
        "        ResBlock(in_channels, out_channels, stride),\n",
        "        ResBlock(out_channels, out_channels, 1)\n",
        "    )\n",
        "    return net \n",
        "  # def create_block(self,in,out,stride):\n",
        "  #   return nn.Sequential(\n",
        "  #   ResBlock(in, out, stride),\n",
        "  #   ResBlock(out,out, 1))\n",
        "        \n",
        "  def forward(self,x):\n",
        "    x = self.rel1(self.bn1(self.conv1(x)))\n",
        "    x = nn.AvgPool2d(4)(self.block4(self.block3(self.block2(self.block1(x)))))\n",
        "    x = x.view(x.size(0),-1) #conversion from 3D to 2D\n",
        "    x = self.lin(x)\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTkDiBGutCV1",
        "colab_type": "code",
        "outputId": "19248a13-784d-4725-9561-7b8412ec5499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "#downloading the data \n",
        "!wget http://pjreddie.com/media/files/cifar.tgz\n",
        "!tar xzf cifar.tgz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-17 17:25:16--  http://pjreddie.com/media/files/cifar.tgz\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://pjreddie.com/media/files/cifar.tgz [following]\n",
            "--2019-12-17 17:25:16--  https://pjreddie.com/media/files/cifar.tgz\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168584360 (161M) [application/octet-stream]\n",
            "Saving to: ‘cifar.tgz’\n",
            "\n",
            "cifar.tgz           100%[===================>] 160.77M  19.7MB/s    in 8.8s    \n",
            "\n",
            "2019-12-17 17:25:26 (18.2 MB/s) - ‘cifar.tgz’ saved [168584360/168584360]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeJL3ytS2QEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preprocessing\n",
        "import numpy as np\n",
        "import random\n",
        "def preprocess(image):\n",
        "    image = np.array(image)\n",
        "    \n",
        "    if random.random() > 0.5:\n",
        "        image = image[::-1,:,:]\n",
        "    \n",
        "    cifar_mean = np.array([0.4914, 0.4822, 0.4465]).reshape(1,1,-1)\n",
        "    cifar_std  = np.array([0.2023, 0.1994, 0.2010]).reshape(1,1,-1)\n",
        "    image = (image - cifar_mean) / cifar_std\n",
        "    \n",
        "    image = image.transpose(2,1,0)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9hLbhpduqDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "data = Path('./cifar')\n",
        "train = data/'train'\n",
        "test = data/'test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qINHUiDMu-IE",
        "colab_type": "code",
        "outputId": "957ad0df-7384-4e8f-8b81-2f432eb012bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train,test"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('cifar/train'), PosixPath('cifar/test'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ4j1_Azu_y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(data/'labels.txt','r') as f:\n",
        "  labels = f.read().split()\n",
        "  label_mapping = dict(zip(labels, list(range(len(labels)))))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qpc2KXLwOb7",
        "colab_type": "code",
        "outputId": "849d45f0-edbc-4657-cd41-6cc2c8331cd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "label_mapping"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'airplane': 0,\n",
              " 'automobile': 1,\n",
              " 'bird': 2,\n",
              " 'cat': 3,\n",
              " 'deer': 4,\n",
              " 'dog': 5,\n",
              " 'frog': 6,\n",
              " 'horse': 7,\n",
              " 'ship': 8,\n",
              " 'truck': 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwkFWeza8dlp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c54a6ce5-aecd-4d26-a622-fa7c0028ad30"
      },
      "source": [
        "import os\n",
        "\n",
        "os.listdir(train)[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'8619_horse.png'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sspcj79-vQ-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating the dataset\n",
        "#try later without creating a list from the files\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class Cifar10Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self,train_path=train,labels=label_mapping,transform=None):\n",
        "    files = os.listdir(train_path)\n",
        "    files = [os.path.join(train_path,x) for x in files]\n",
        "\n",
        "    self.files = files\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    image = Image.open(self.files[idx])\n",
        "    image = preprocess(image)\n",
        "    image = image.astype(np.float32)\n",
        "    label = label_mapping[self.files[idx].split('_')[-1].split('.')[0]]\n",
        "\n",
        "    if self.transform:\n",
        "      image = self.tranform(image)\n",
        "\n",
        "    return (image,label)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByDoch-Xv5T7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = Cifar10Dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5DScyu65JSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "testset = Cifar10Dataset(data/\"test\", transform=None)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CsgNAid6Vx9",
        "colab_type": "code",
        "outputId": "5c3ff25c-cf01-41b3-efb4-69977ba381f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")     #Check whether a GPU is present.\n",
        "\n",
        "clf = ResNet()\n",
        "clf.to(device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (rel1): ReLU()\n",
              "  (block1): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (block2): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (block3): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (block4): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (lin): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omdCJpbv6806",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(clf.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 200], gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYzs7eLoF3AY",
        "colab_type": "code",
        "outputId": "35ad1b78-edfd-4067-8dc4-8401e5f530f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "import time\n",
        "for epoch in range(5):\n",
        "  losses = []\n",
        "  scheduler.step()\n",
        "\n",
        "  start = time.time()\n",
        "  for inputs, targets in trainloader:\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "    optimizer.zero_grad()                 # Zero the gradients\n",
        "\n",
        "    outputs = clf(inputs)                 # Forward pass\n",
        "    loss = criterion(outputs, targets)    # Compute the Loss\n",
        "    loss.backward()                       # Compute the Gradients\n",
        "\n",
        "    optimizer.step()                      # Updated the weights\n",
        "    losses.append(loss.item())\n",
        "    end = time.time()\n",
        "\n",
        "\n",
        "\n",
        "  # Evaluate\n",
        "  clf.eval()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets in testloader:\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "      outputs = clf(inputs)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += targets.size(0)\n",
        "      correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "  print(f'Epoch : {epoch+4}  Loss: {loss} Test Acc : {100.*correct/total}')\n",
        "  print('--------------------------------------------------------------')\n",
        "  clf.train()    \n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 4  Loss: 0.7643682956695557 Test Acc : 69.63999938964844\n",
            "--------------------------------------------------------------\n",
            "Epoch : 5  Loss: 0.7147625684738159 Test Acc : 67.52999877929688\n",
            "--------------------------------------------------------------\n",
            "Epoch : 6  Loss: 0.7407170534133911 Test Acc : 66.08999633789062\n",
            "--------------------------------------------------------------\n",
            "Epoch : 7  Loss: 0.4705318510532379 Test Acc : 72.6500015258789\n",
            "--------------------------------------------------------------\n",
            "Epoch : 8  Loss: 0.7329400777816772 Test Acc : 71.58000183105469\n",
            "--------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RXeRcc7Hjnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}