{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR_Dataset_with_ResNet_from_Scratch",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishakBharadwaj94/Resnets_from_scratch/blob/master/CIFAR_Dataset_with_ResNet_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BDjwUDIgCE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urLU8eRFg1s6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlock(nn.Module):     \n",
        "  expansion = 1\n",
        "  def __init__(self, in_channels, out_channels, stride=1):\n",
        "    super(ResBlock, self).__init__()\n",
        "\n",
        "    # Conv Layer 1\n",
        "    self.conv1 = nn.Conv2d(\n",
        "        in_channels=in_channels, out_channels=out_channels,\n",
        "        kernel_size=(3, 3), stride=stride, padding=1, bias=False\n",
        "    )\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    # Conv Layer 2\n",
        "    self.conv2 = nn.Conv2d(\n",
        "        in_channels=out_channels, out_channels=out_channels,\n",
        "        kernel_size=(3, 3), stride=1, padding=1, bias=False\n",
        "    )\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_channels != out_channels:\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(\n",
        "              in_channels=in_channels, out_channels=out_channels,\n",
        "              kernel_size=(1, 1), stride=stride, bias=False\n",
        "          ),\n",
        "          nn.BatchNorm2d(out_channels)\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = nn.ReLU()(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmnSaYW7lRBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "  def __init__(self,classes=10):\n",
        "\n",
        "    super(ResNet,self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=3,out_channels=64,kernel_size=(3,3),stride=1, padding=1,bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.rel1 = nn.ReLU()\n",
        "\n",
        "    self.block1 = self.create_block(64,64,1)\n",
        "    self.block2 = self.create_block(64,128,2)\n",
        "    self.block3 = self.create_block(128,256,2)\n",
        "    self.block4 = self.create_block(256,512,2)\n",
        "\n",
        "    self.lin = nn.Linear(512,classes)\n",
        "\n",
        "    #1 block has two reblocks\n",
        "\n",
        "  def create_block(self, in_channels, out_channels, stride):\n",
        "    \n",
        "    net = nn.Sequential(\n",
        "        ResBlock(in_channels, out_channels, stride),\n",
        "        ResBlock(out_channels, out_channels, 1)\n",
        "    )\n",
        "    return net \n",
        "  # def create_block(self,in,out,stride):\n",
        "  #   return nn.Sequential(\n",
        "  #   ResBlock(in, out, stride),\n",
        "  #   ResBlock(out,out, 1))\n",
        "        \n",
        "  def forward(self,x):\n",
        "    x = self.rel1(self.bn1(self.conv1(x)))\n",
        "    x = nn.AvgPool2d(4)(self.block4(self.block3(self.block2(self.block1(x)))))\n",
        "    x = x.view(x.size(0),-1) #conversion from 3D to 2D\n",
        "    x = self.lin(x)\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTkDiBGutCV1",
        "colab_type": "code",
        "outputId": "937264e2-fed1-40bd-e620-ba655316cab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "#downloading the data \n",
        "!wget http://pjreddie.com/media/files/cifar.tgz\n",
        "!tar xzf cifar.tgz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-15 16:35:08--  http://pjreddie.com/media/files/cifar.tgz\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://pjreddie.com/media/files/cifar.tgz [following]\n",
            "--2019-12-15 16:35:08--  https://pjreddie.com/media/files/cifar.tgz\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168584360 (161M) [application/octet-stream]\n",
            "Saving to: ‘cifar.tgz’\n",
            "\n",
            "cifar.tgz           100%[===================>] 160.77M  21.9MB/s    in 7.8s    \n",
            "\n",
            "2019-12-15 16:35:17 (20.7 MB/s) - ‘cifar.tgz’ saved [168584360/168584360]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeJL3ytS2QEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preprocessing\n",
        "import numpy as np\n",
        "import random\n",
        "def preprocess(image):\n",
        "    image = np.array(image)\n",
        "    \n",
        "    if random.random() > 0.5:\n",
        "        image = image[::-1,:,:]\n",
        "    \n",
        "    cifar_mean = np.array([0.4914, 0.4822, 0.4465]).reshape(1,1,-1)\n",
        "    cifar_std  = np.array([0.2023, 0.1994, 0.2010]).reshape(1,1,-1)\n",
        "    image = (image - cifar_mean) / cifar_std\n",
        "    \n",
        "    image = image.transpose(2,1,0)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9hLbhpduqDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "data = Path('./cifar')\n",
        "train = data/'train'\n",
        "test = data/'test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qINHUiDMu-IE",
        "colab_type": "code",
        "outputId": "b440fc8f-1cbc-49c0-f25d-91ac6119e3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train,test"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('cifar/train'), PosixPath('cifar/test'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ4j1_Azu_y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(data/'labels.txt','r') as f:\n",
        "  labels = f.read().split()\n",
        "  label_mapping = dict(zip(labels, list(range(len(labels)))))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qpc2KXLwOb7",
        "colab_type": "code",
        "outputId": "83a35a75-cac0-415b-c1fc-a7b8490eddf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "label_mapping"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'airplane': 0,\n",
              " 'automobile': 1,\n",
              " 'bird': 2,\n",
              " 'cat': 3,\n",
              " 'deer': 4,\n",
              " 'dog': 5,\n",
              " 'frog': 6,\n",
              " 'horse': 7,\n",
              " 'ship': 8,\n",
              " 'truck': 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sspcj79-vQ-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating the dataset\n",
        "#try later without creating a list from the files\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class Cifar10Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self,train_path=train,labels=label_mapping,transform=None):\n",
        "    files = os.listdir(train_path)\n",
        "    files = [os.path.join(train_path,x) for x in files]\n",
        "\n",
        "    self.files = files\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    image = Image.open(self.files[idx])\n",
        "    image = preprocess(image)\n",
        "    image = image.astype(np.float32)\n",
        "    label = label_mapping[self.files[idx].split('_')[-1].split('.')[0]]\n",
        "\n",
        "    if self.transform:\n",
        "      image = self.tranform(image)\n",
        "\n",
        "    return (image,label)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByDoch-Xv5T7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = Cifar10Dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5DScyu65JSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "testset = Cifar10Dataset(data/\"test\", transform=None)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CsgNAid6Vx9",
        "colab_type": "code",
        "outputId": "e1a98790-3b84-4661-fdfa-dc1ef5a5b79b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")     #Check whether a GPU is present.\n",
        "\n",
        "clf = ResNet()\n",
        "clf.to(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (rel1): ReLU()\n",
              "  (block1): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (block2): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (block3): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (block4): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (lin): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omdCJpbv6806",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(clf.parameters(), lr=0.1)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 200], gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYzs7eLoF3AY",
        "colab_type": "code",
        "outputId": "aa6d6073-7f25-4755-8cc2-d685cd54d65a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "source": [
        "import time\n",
        "for epoch in range(5):\n",
        "    losses = []\n",
        "    scheduler.step()\n",
        "    # Train\n",
        "    start = time.time()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()                 # Zero the gradients\n",
        "\n",
        "        outputs = clf(inputs)                 # Forward pass\n",
        "        loss = criterion(outputs, targets)    # Compute the Loss\n",
        "        loss.backward()                       # Compute the Gradients\n",
        "\n",
        "        optimizer.step()                      # Updated the weights\n",
        "        losses.append(loss.item())\n",
        "        end = time.time()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "          print('Batch Index : %d Loss : %.3f Time : %.3f seconds ' % (batch_idx, np.mean(losses), end - start))\n",
        "      \n",
        "          start = time.time()\n",
        "    # Evaluate\n",
        "    clf.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "          inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "          outputs = clf(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += targets.size(0)\n",
        "          correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "      print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))\n",
        "      print('--------------------------------------------------------------')\n",
        "    clf.train()    \n",
        "    "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch Index : 0 Loss : 2.453 Time : 0.803 seconds \n",
            "Batch Index : 100 Loss : 2.958 Time : 48.813 seconds \n",
            "Batch Index : 200 Loss : 2.499 Time : 48.750 seconds \n",
            "Batch Index : 300 Loss : 2.314 Time : 48.847 seconds \n",
            "Epoch : 0 Test Acc : 19.690\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 1.707 Time : 0.653 seconds \n",
            "Batch Index : 100 Loss : 1.801 Time : 48.618 seconds \n",
            "Batch Index : 200 Loss : 1.767 Time : 48.781 seconds \n",
            "Batch Index : 300 Loss : 1.748 Time : 48.740 seconds \n",
            "Epoch : 1 Test Acc : 32.720\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 1.722 Time : 0.646 seconds \n",
            "Batch Index : 100 Loss : 1.638 Time : 48.620 seconds \n",
            "Batch Index : 200 Loss : 1.613 Time : 49.481 seconds \n",
            "Batch Index : 300 Loss : 1.592 Time : 49.491 seconds \n",
            "Epoch : 2 Test Acc : 41.940\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 1.483 Time : 0.636 seconds \n",
            "Batch Index : 100 Loss : 1.471 Time : 49.441 seconds \n",
            "Batch Index : 200 Loss : 1.460 Time : 49.413 seconds \n",
            "Batch Index : 300 Loss : 1.444 Time : 49.489 seconds \n",
            "Epoch : 3 Test Acc : 46.820\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 1.375 Time : 0.641 seconds \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2c350d66903a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                      \u001b[0;31m# Updated the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RXeRcc7Hjnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}